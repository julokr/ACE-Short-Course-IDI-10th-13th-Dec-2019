{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Introduction to Natural Language Processing for Text\n",
    "</h1>\n",
    "<b>Author: </b> <a href=\"https://towardsdatascience.com/@ventsislav94\">Ventsislav Yordanov</a><br/>\n",
    "<b>Original article: </b> <a href=\"https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63\">towardsdatascience.com</a><br/><br/>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2000/1*CuPIUoh1nvh_r1Ssqmy8SA.jpeg\"/>\n",
    "\n",
    "<p id=\"f027\">\n",
    "After reading this blog post, you’ll know some basic techniques to\n",
    "<strong>\n",
    "extract features from\n",
    "</strong>\n",
    "some\n",
    "<strong>\n",
    "text\n",
    "</strong>\n",
    ", so you can use these features as\n",
    "<strong>\n",
    "input\n",
    "</strong>\n",
    "for\n",
    "<strong>\n",
    "machine learning models\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "<h1 id=\"107b\">\n",
    "What is NLP (Natural Language Processing)?\n",
    "</h1>\n",
    "<p id=\"2584\">\n",
    "<strong>\n",
    "NLP\n",
    "</strong>\n",
    "is a subfield of computer science and artificial intelligence concerned with interactions between computers and human (natural) languages. It is used to apply\n",
    "<strong>\n",
    "machine learning\n",
    "</strong>\n",
    "algorithms to\n",
    "<strong>\n",
    "text\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "speech\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "<p id=\"4b9f\">\n",
    "For example, we can use NLP to create systems like\n",
    "<strong>\n",
    "speech recognition\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "document summarization\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "machine translation\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "spam detection\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "named entity recognition\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "question answering, autocomplete, predictive typing\n",
    "</strong>\n",
    "and so on.\n",
    "</p>\n",
    "<p id=\"cdbc\">\n",
    "Nowadays, most of us have smartphones that have speech recognition. These smartphones use NLP to understand what is said. Also, many people use laptops which operating system has a built-in speech recognition.\n",
    "</p>\n",
    "<h2 id=\"c54d\">\n",
    "Some Examples\n",
    "</h2>\n",
    "<p id=\"b58d\">\n",
    "<strong>\n",
    "Cortana\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*TXj0kr4jVrtLtmvxZFu8Lw.png\"/>\n",
    "<br/>\n",
    "<br/>\n",
    "<p id=\"60dd\">\n",
    "The Microsoft OS has a virtual assistant called\n",
    "<a href=\"https://support.microsoft.com/en-us/help/17214/windows-10-what-is\">\n",
    "<strong>\n",
    "Cortana\n",
    "</strong>\n",
    "</a>\n",
    "that can recognize a\n",
    "<strong>\n",
    "natural voice\n",
    "</strong>\n",
    ". You can use it to set up reminders, open apps, send emails, play games, track flights and packages, check the weather and so on.\n",
    "</p>\n",
    "<p id=\"0c62\">\n",
    "You can read more for Cortana commands from\n",
    "<a href=\"https://www.howtogeek.com/225458/15-things-you-can-do-with-cortana-on-windows-10/\">\n",
    "here\n",
    "</a>\n",
    ".\n",
    "</p>\n",
    "<p id=\"cd7f\">\n",
    "<strong>\n",
    "Siri\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*-AuKCZbXIVOhI-AgX4J8PQ.jpeg\"/>\n",
    "<br/>\n",
    "<p id=\"dcd6\">\n",
    "Siri is a virtual assistant of the Apple Inc.’s iOS, watchOS, macOS, HomePod, and tvOS operating systems. Again, you can do a lot of things with\n",
    "<strong>\n",
    "voice\n",
    "</strong>\n",
    "<strong>\n",
    "commands\n",
    "</strong>\n",
    ": start a call, text someone, send an email, set a timer, take a picture, open an app, set an alarm, use navigation and so on.\n",
    "</p>\n",
    "\n",
    "<p id=\"95e8\">\n",
    "<a href=\"https://www.cnet.com/how-to/the-complete-list-of-siri-commands/\">\n",
    "Here\n",
    "</a>\n",
    "is a complete list of all Siri commands.\n",
    "</p>\n",
    "<p id=\"45f3\">\n",
    "<strong>\n",
    "Gmail\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*fTPhu7PqgIbnngbWG5zFWA.gif\"/>\n",
    "<br/>\n",
    "<p id=\"0391\">\n",
    "The famous email service\n",
    "<strong>\n",
    "Gmail\n",
    "</strong>\n",
    "developed by Google is using\n",
    "<strong>\n",
    "spam detection\n",
    "</strong>\n",
    "to filter out some spam emails.\n",
    "</p>\n",
    "<h1 id=\"da92\">\n",
    "Introduction to the NLTK library for Python\n",
    "</h1>\n",
    "<p id=\"5a49\">\n",
    "NLTK (\n",
    "<strong>\n",
    "Natural Language Toolkit\n",
    "</strong>\n",
    ") is a\n",
    "<strong>\n",
    "leading platform\n",
    "</strong>\n",
    "for building Python programs to work with\n",
    "<strong>\n",
    "human language data\n",
    "</strong>\n",
    ". It provides easy-to-use interfaces to\n",
    "<strong>\n",
    "many\n",
    "</strong>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Text_corpus\">\n",
    "<strong>\n",
    "corpora\n",
    "</strong>\n",
    "</a>\n",
    "and\n",
    "<strong>\n",
    "lexical resources\n",
    "</strong>\n",
    ". Also, it contains a suite of\n",
    "<strong>\n",
    "text processing libraries\n",
    "</strong>\n",
    "for classification, tokenization, stemming, tagging, parsing, and semantic reasoning. Best of all, NLTK is a free, open source, community-driven project.\n",
    "</p>\n",
    "<p id=\"024d\">\n",
    "We’ll use this toolkit to show some basics of the natural language processing field. For the examples below, I’ll assume that we have imported the NLTK toolkit. We can do this like this:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 id=\"4164\">\n",
    "The Basics of NLP for Text\n",
    "</h1>\n",
    "<p id=\"4e0d\">\n",
    "In this article, we’ll cover the following topics:\n",
    "</p>\n",
    "<ol>\n",
    "<li id=\"5bae\">\n",
    "Sentence Tokenization\n",
    "</li>\n",
    "<li id=\"8a7f\">\n",
    "Word Tokenization\n",
    "</li>\n",
    "<li id=\"6c69\">\n",
    "Text Lemmatization and Stemming\n",
    "</li>\n",
    "<li id=\"4146\">\n",
    "Stop Words\n",
    "</li>\n",
    "<li id=\"69c2\">\n",
    "Regex\n",
    "</li>\n",
    "<li id=\"9269\">\n",
    "Bag-of-Words\n",
    "</li>\n",
    "<li id=\"85ee\">\n",
    "TF-IDF\n",
    "</li>\n",
    "</ol>\n",
    "<h2 id=\"9773\">\n",
    "1. Sentence Tokenization\n",
    "</h2>\n",
    "<p id=\"416a\">\n",
    "Sentence tokenization (also called\n",
    "<strong>\n",
    "sentence segmentation\n",
    "</strong>\n",
    ") is the problem of\n",
    "<strong>\n",
    "dividing a string\n",
    "</strong>\n",
    "of written language\n",
    "<strong>\n",
    "into\n",
    "</strong>\n",
    "its component\n",
    "<strong>\n",
    "sentences\n",
    "</strong>\n",
    ". The idea here looks very simple. In English and some other languages, we can split apart the sentences whenever we see a punctuation mark.\n",
    "</p>\n",
    "<p id=\"99b8\">\n",
    "However, even in English, this problem is not trivial due to the use of full stop character for abbreviations. When processing plain text, tables of abbreviations that contain periods can help us to prevent incorrect assignment of\n",
    "<strong>\n",
    "sentence boundaries\n",
    "</strong>\n",
    ". In many cases, we use libraries to do that job for us, so don’t worry too much for the details for now.\n",
    "</p>\n",
    "<p id=\"55a5\">\n",
    "<strong>\n",
    "Example\n",
    "</strong>\n",
    ":\n",
    "</p>\n",
    "<p id=\"9f51\">\n",
    "Let’s look a piece of text about a famous board game called backgammon.\n",
    "</p>\n",
    "<blockquote>\n",
    "<p id=\"4012\">\n",
    "Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\n",
    "</p>\n",
    "</blockquote>\n",
    "<p id=\"5d1a\">\n",
    "To apply a sentence tokenization with NLTK we can use the\n",
    "<code>\n",
    "nltk.sent_tokenize\n",
    "</code>\n",
    "function.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\"\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"e25f\">\n",
    "As an output, we get the 3 component sentences separately.\n",
    "</p>\n",
    "<h2 id=\"2067\">\n",
    "2. Word Tokenization\n",
    "</h2>\n",
    "<p id=\"159f\">\n",
    "Word tokenization (also called\n",
    "<strong>\n",
    "word segmentation\n",
    "</strong>\n",
    ") is the problem of\n",
    "<strong>\n",
    "dividing a string\n",
    "</strong>\n",
    "of written language\n",
    "<strong>\n",
    "into\n",
    "</strong>\n",
    "its component\n",
    "<strong>\n",
    "words\n",
    "</strong>\n",
    ". In English and many other languages using some form of Latin alphabet, space is a good approximation of a word divider.\n",
    "</p>\n",
    "<p id=\"44b0\">\n",
    "However, we still can have problems if we only split by space to achieve the wanted results. Some English compound nouns are variably written and sometimes they contain a space. In most cases, we use a library to achieve the wanted results, so again don’t worry too much for the details.\n",
    "</p>\n",
    "<p id=\"5af4\">\n",
    "<strong>\n",
    "Example\n",
    "</strong>\n",
    ":\n",
    "</p>\n",
    "<p id=\"8a66\">\n",
    "Let’s use the sentences from the previous step and see how we can apply word tokenization on them. We can use the\n",
    "<code>\n",
    "nltk.word_tokenize\n",
    "</code>\n",
    "function.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    print(words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<h2 id=\"0c8d\">\n",
    "Text Lemmatization and Stemming\n",
    "</h2>\n",
    "<p id=\"cc28\">\n",
    "For grammatical reasons, documents can contain\n",
    "<strong>\n",
    "different forms of a word\n",
    "</strong>\n",
    "such as\n",
    "<em>\n",
    "drive\n",
    "</em>\n",
    ",\n",
    "<em>\n",
    "drives\n",
    "</em>\n",
    ",\n",
    "<em>\n",
    "driving\n",
    "</em>\n",
    ". Also, sometimes we have\n",
    "<strong>\n",
    "related words\n",
    "</strong>\n",
    "with a similar meaning, such as\n",
    "<em>\n",
    "nation\n",
    "</em>\n",
    ",\n",
    "<em>\n",
    "national\n",
    "</em>\n",
    ",\n",
    "<em>\n",
    "nationality\n",
    "</em>\n",
    ".\n",
    "</p>\n",
    "<blockquote>\n",
    "<p id=\"6e80\">\n",
    "The goal of both\n",
    "<strong>\n",
    "stemming\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "lemmatization\n",
    "</strong>\n",
    "is to\n",
    "<strong>\n",
    "reduce\n",
    "</strong>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Inflection\">\n",
    "<strong>\n",
    "inflectional\n",
    "</strong>\n",
    "</a>\n",
    "<strong>\n",
    "forms\n",
    "</strong>\n",
    "and sometimes derivationally related forms\n",
    "<strong>\n",
    "</strong>\n",
    "of a\n",
    "<strong>\n",
    "word to\n",
    "</strong>\n",
    "a\n",
    "<strong>\n",
    "common base form\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "</blockquote>\n",
    "<p id=\"c85e\">\n",
    "Source:\n",
    "<a href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\">\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n",
    "</a>\n",
    "</p>\n",
    "<p id=\"79aa\">\n",
    "<strong>\n",
    "Examples\n",
    "</strong>\n",
    ":\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"993f\">\n",
    "am, are, is\n",
    "<code>\n",
    "=&gt;\n",
    "</code>\n",
    "be\n",
    "</li>\n",
    "<li id=\"e377\">\n",
    "dog, dogs, dog’s, dogs’\n",
    "<code>\n",
    "=&gt;\n",
    "</code>\n",
    "dog\n",
    "</li>\n",
    "</ul>\n",
    "<p id=\"9372\">\n",
    "The result of this mapping applied on a text will be something like that:\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"377f\">\n",
    "the boy’s dogs are different sizes\n",
    "<code>\n",
    "=&gt;\n",
    "</code>\n",
    "the boy dog be differ size\n",
    "</li>\n",
    "</ul>\n",
    "<p id=\"49c9\">\n",
    "Stemming and lemmatization are special cases of\n",
    "<strong>\n",
    "normalization\n",
    "</strong>\n",
    ". However, they are different from each other.\n",
    "</p>\n",
    "\n",
    "<blockquote>\n",
    "<p id=\"67df\">\n",
    "<strong>\n",
    "Stemming\n",
    "</strong>\n",
    "usually refers to a\n",
    "<strong>\n",
    "crude\n",
    "</strong>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Heuristic\">\n",
    "<strong>\n",
    "heuristic\n",
    "</strong>\n",
    "</a>\n",
    "<strong>\n",
    "process\n",
    "</strong>\n",
    "that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes.\n",
    "</p>\n",
    "<p id=\"6723\">\n",
    "<strong>\n",
    "Lemmatization\n",
    "</strong>\n",
    "usually refers to\n",
    "<strong>\n",
    "doing things properly\n",
    "</strong>\n",
    "with the use of a\n",
    "<strong>\n",
    "vocabulary\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "morphological analysis\n",
    "</strong>\n",
    "of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the\n",
    "<strong>\n",
    "lemma\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "</blockquote>\n",
    "<p id=\"741d\">\n",
    "Source:\n",
    "<a href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\">\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n",
    "</a>\n",
    "</p>\n",
    "<p id=\"fa62\">\n",
    "The difference is that a\n",
    "<strong>\n",
    "stemmer\n",
    "</strong>\n",
    "operates\n",
    "<strong>\n",
    "without knowledge of the context\n",
    "</strong>\n",
    ", and therefore cannot understand the difference between words which have different meaning depending on part of speech. But the stemmers also have some advantages, they are\n",
    "<strong>\n",
    "easier to implement\n",
    "</strong>\n",
    "and usually\n",
    "<strong>\n",
    "run faster\n",
    "</strong>\n",
    ". Also, the reduced “accuracy” may not matter for some applications.\n",
    "</p>\n",
    "<p id=\"833e\">\n",
    "<strong>\n",
    "Examples:\n",
    "</strong>\n",
    "</p>\n",
    "<ol>\n",
    "<li id=\"6ce8\">\n",
    "The word “better” has “good” as its lemma. This link is missed by stemming, as it requires a dictionary look-up.\n",
    "</li>\n",
    "<li id=\"a8ff\">\n",
    "The word “play” is the base form for the word “playing”, and hence this is matched in both stemming and lemmatization.\n",
    "</li>\n",
    "<li id=\"a7fc\">\n",
    "The word “meeting” can be either the base form of a noun or a form of a verb (“to meet”) depending on the context; e.g., “in our last meeting” or “We are meeting again tomorrow”. Unlike stemming, lemmatization attempts to select the correct lemma depending on the context.\n",
    "</li>\n",
    "</ol>\n",
    "<p id=\"c803\">\n",
    "After we know what’s the difference, let’s see some examples using the NLTK tool.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word, pos):\n",
    "    \"\"\"\n",
    "    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)\n",
    "    \"\"\"\n",
    "    print(\"Stemmer:\", stemmer.stem(word))\n",
    "    print(\"Lemmatizer:\", lemmatizer.lemmatize(word, pos))\n",
    "    print()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word = \"seen\", pos = wordnet.VERB)\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word = \"drove\", pos = wordnet.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 id=\"0b95\">\n",
    "Stop words\n",
    "</h2>\n",
    "<img src=\"https://miro.medium.com/max/820/1*kMf7dZW4jTyaq1hxjA0pgg.png\"/>\n",
    "<p id=\"37bf\">\n",
    "Stop words are words which are\n",
    "<strong>\n",
    "filtered out\n",
    "</strong>\n",
    "before or after processing of text. When applying machine learning to text, these words can add a lot of\n",
    "<strong>\n",
    "noise\n",
    "</strong>\n",
    ". That’s why we want to remove these\n",
    "<strong>\n",
    "irrelevant words\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "<p id=\"1fc5\">\n",
    "Stop words\n",
    "<strong>\n",
    "usually\n",
    "</strong>\n",
    "refer to the\n",
    "<strong>\n",
    "most common words\n",
    "</strong>\n",
    "such as “\n",
    "<strong>\n",
    "and\n",
    "</strong>\n",
    "”, “\n",
    "<strong>\n",
    "the\n",
    "</strong>\n",
    "”, “\n",
    "<strong>\n",
    "a\n",
    "</strong>\n",
    "” in a language, but there is\n",
    "<strong>\n",
    "no single universal list\n",
    "</strong>\n",
    "of stopwords. The list of the stop words can change depending on your application.\n",
    "</p>\n",
    "<p id=\"7da9\">\n",
    "The NLTK tool has a predefined list of stopwords that refers to the most common words. If you use it for your first time, you need to download the stop words using this code:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p>\n",
    "Once we complete the downloading, we can load the\n",
    "<code>\n",
    "stopwords\n",
    "</code>\n",
    "package from the\n",
    "<code>\n",
    "nltk.corpus\n",
    "</code>\n",
    "and use it to load the stop words.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"f34b\">\n",
    "Let’s see how we can remove the stop words from a sentence.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentence = \"Backgammon is one of the oldest known board games.\"\n",
    "\n",
    "words = nltk.word_tokenize(sentence)\n",
    "without_stop_words = [word for word in words if not word in stop_words]\n",
    "print(without_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"66ae\">\n",
    "If you’re not familiar with the\n",
    "<a href=\"/python-basics-list-comprehensions-631278f22c40\">\n",
    "<strong>\n",
    "list comprehensions\n",
    "</strong>\n",
    "in Python\n",
    "</a>\n",
    ". Here is another way to achieve the same result.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentence = \"Backgammon is one of the oldest known board games.\"\n",
    "\n",
    "words = nltk.word_tokenize(sentence)\n",
    "without_stop_words = []\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        without_stop_words.append(word)\n",
    "\n",
    "print(without_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<p id=\"06a9\">\n",
    "However, keep in mind that\n",
    "<strong>\n",
    "list comprehensions\n",
    "</strong>\n",
    "are\n",
    "<strong>\n",
    "faster\n",
    "</strong>\n",
    "because they are\n",
    "<strong>\n",
    "optimized\n",
    "</strong>\n",
    "for the Python interpreter to spot a predictable pattern during looping.\n",
    "</p>\n",
    "<p id=\"5463\">\n",
    "You might wonder why we convert our list into a\n",
    "<a href=\"https://docs.python.org/3/tutorial/datastructures.html#sets\">\n",
    "<strong>\n",
    "set\n",
    "</strong>\n",
    "</a>\n",
    ". Set is an abstract data type that can store unique values, without any particular order. The\n",
    "<strong>\n",
    "search operation\n",
    "</strong>\n",
    "<strong>\n",
    "in a set\n",
    "</strong>\n",
    "is\n",
    "<strong>\n",
    "much faster\n",
    "</strong>\n",
    "<strong>\n",
    "than\n",
    "</strong>\n",
    "the search operation\n",
    "<strong>\n",
    "in a list\n",
    "</strong>\n",
    ". For a small number of words, there is no big difference, but if you have a large number of words it’s highly recommended to use the set type.\n",
    "</p>\n",
    "<p id=\"74fb\">\n",
    "If you want to learn more about the time consuming between the different operations for the different data structures you can look at this awesome\n",
    "<a href=\"http://bigocheatsheet.com/\">\n",
    "cheat sheet\n",
    "</a>\n",
    ".\n",
    "</p>\n",
    "<h2 id=\"7371\">\n",
    "Regex\n",
    "</h2>\n",
    "<img src=\"https://miro.medium.com/max/1052/1*l_EB11yQfbZsKLFr8ZckuQ.jpeg\"/>\n",
    "<p id=\"c323\">\n",
    "A\n",
    "<strong>\n",
    "regular expression\n",
    "</strong>\n",
    ",\n",
    "<strong>\n",
    "regex\n",
    "</strong>\n",
    ", or\n",
    "<strong>\n",
    "regexp\n",
    "</strong>\n",
    "is a sequence of characters that define a\n",
    "<strong>\n",
    "search pattern\n",
    "</strong>\n",
    ". Let’s see some basics.\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"da70\">\n",
    "<code>\n",
    ".\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "any character\n",
    "</strong>\n",
    "<strong>\n",
    "except newline\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"72dc\">\n",
    "<code>\n",
    "\\w\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "word\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"5207\">\n",
    "<code>\n",
    "\\d\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "digit\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"6735\">\n",
    "<code>\n",
    "\\s\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "whitespace\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"d972\">\n",
    "<code>\n",
    "\\W\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "not word\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"543c\">\n",
    "<code>\n",
    "\\D\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "not digit\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"2122\">\n",
    "<code>\n",
    "\\S\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "not whitespace\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"e917\">\n",
    "<code>\n",
    "[abc]\n",
    "</code>\n",
    "- match\n",
    "<strong>\n",
    "any\n",
    "</strong>\n",
    "of a, b, or c\n",
    "</li>\n",
    "<li id=\"14cf\">\n",
    "<code>\n",
    "[\n",
    "<strong>\n",
    "^\n",
    "</strong>\n",
    "abc]\n",
    "</code>\n",
    "-\n",
    "<strong>\n",
    "not\n",
    "</strong>\n",
    "match a, b, or c\n",
    "</li>\n",
    "<li id=\"7cc6\">\n",
    "<code>\n",
    "[a\n",
    "<strong>\n",
    "-\n",
    "</strong>\n",
    "g]\n",
    "</code>\n",
    "- match a character\n",
    "<strong>\n",
    "between\n",
    "</strong>\n",
    "a &amp; g\n",
    "</li>\n",
    "</ul>\n",
    "<blockquote>\n",
    "<p id=\"3909\">\n",
    "Regular expressions use the\n",
    "<strong>\n",
    "backslash character\n",
    "</strong>\n",
    "(\n",
    "<code>\n",
    "'\\'\n",
    "</code>\n",
    ") to indicate special forms or to allow special characters to be used without invoking their special meaning. This\n",
    "<strong>\n",
    "collides with Python’s usage\n",
    "</strong>\n",
    "of the same character for the same purpose in string literals; for example, to match a literal backslash, one might have to write\n",
    "<code>\n",
    "'\\\\\\\\'\n",
    "</code>\n",
    "as the pattern string, because the regular expression must be\n",
    "<code>\n",
    "\\\\\n",
    "</code>\n",
    ", and each backslash must be expressed as\n",
    "<code>\n",
    "\\\\\n",
    "</code>\n",
    "inside a regular Python string literal.\n",
    "</p>\n",
    "<p id=\"86c7\">\n",
    "The solution is to use Python’s\n",
    "<strong>\n",
    "raw string notation\n",
    "</strong>\n",
    "for regular expression patterns; backslashes are not handled in any special way in a string literal\n",
    "<strong>\n",
    "prefixed with\n",
    "</strong>\n",
    "<code>\n",
    "<strong>\n",
    "'r'\n",
    "</strong>\n",
    "</code>\n",
    ". So\n",
    "<code>\n",
    "r\"\\n\"\n",
    "</code>\n",
    "is a two-character string containing\n",
    "<code>\n",
    "'\\'\n",
    "</code>\n",
    "and\n",
    "<code>\n",
    "'n'\n",
    "</code>\n",
    ", while\n",
    "<code>\n",
    "\"\\n\"\n",
    "</code>\n",
    "is a one-character string containing a newline. Usually, patterns will be expressed in Python code using this raw string notation.\n",
    "</p>\n",
    "</blockquote>\n",
    "<p id=\"ba7d\">\n",
    "Source:\n",
    "<a href=\"https://docs.python.org/3/library/re.html?highlight=regex\">\n",
    "https://docs.python.org/3/library/re.html?highlight=regex\n",
    "</a>\n",
    "</p>\n",
    "<p id=\"adfa\">\n",
    "We can use regex to apply\n",
    "<strong>\n",
    "additional filtering\n",
    "</strong>\n",
    "to our text. For example, we can remove all the non-words characters. In many cases, we don’t need the punctuation marks and it’s easy to remove them with regex.\n",
    "</p>\n",
    "<p id=\"1194\">\n",
    "In Python, the\n",
    "<code>\n",
    "<strong>\n",
    "re\n",
    "</strong>\n",
    "</code>\n",
    "module provides regular expression matching operations similar to those in Perl. We can use the\n",
    "<code>\n",
    "<strong>\n",
    "re.sub\n",
    "</strong>\n",
    "</code>\n",
    "function to replace the matches for a pattern with a replacement string. Let’s see an example when we replace all non-words with the space character.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "sentence = \"The development of snowboarding was inspired by skateboarding, sledding, surfing and skiing.\"\n",
    "pattern = r\"[^\\w]\"\n",
    "print(re.sub(pattern, \" \", sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"e383\">\n",
    "A regular expression is a powerful tool and we can create much more complex patterns. If you want to learn more about regex I can recommend you to try these 2 web apps:\n",
    "<a href=\"https://regexr.com/\">\n",
    "regex\n",
    "</a>\n",
    "r,\n",
    "<a href=\"https://regex101.com/\">\n",
    "regex101\n",
    "</a>\n",
    ".\n",
    "</p>\n",
    "<h2 id=\"01b2\">\n",
    "Bag-of-words\n",
    "</h2>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/512/1*RPezKXGUUwla-JP52OnZxA.png\"/>\n",
    "\n",
    "<p id=\"134b\">\n",
    "Machine learning algorithms cannot work with raw text directly, we need to convert the text into vectors of numbers. This is called\n",
    "<a href=\"https://en.wikipedia.org/wiki/Feature_extraction\">\n",
    "<strong>\n",
    "feature extraction\n",
    "</strong>\n",
    "</a>\n",
    ".\n",
    "</p>\n",
    "<p id=\"1f64\">\n",
    "The\n",
    "<strong>\n",
    "bag-of-words\n",
    "</strong>\n",
    "model is a\n",
    "<strong>\n",
    "popular\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "simple\n",
    "</strong>\n",
    "<strong>\n",
    "feature extraction technique\n",
    "</strong>\n",
    "used when we work with text. It describes the occurrence of each word within a document.\n",
    "</p>\n",
    "<p id=\"fffd\">\n",
    "To use this model, we need to:\n",
    "</p>\n",
    "<ol>\n",
    "<li id=\"d244\">\n",
    "Design a\n",
    "<strong>\n",
    "vocabulary\n",
    "</strong>\n",
    "of known words (also called\n",
    "<strong>\n",
    "tokens\n",
    "</strong>\n",
    ")\n",
    "</li>\n",
    "<li id=\"25aa\">\n",
    "Choose a\n",
    "<strong>\n",
    "measure of the presence\n",
    "</strong>\n",
    "of known words\n",
    "</li>\n",
    "</ol>\n",
    "<p id=\"6447\">\n",
    "Any information about\n",
    "<strong>\n",
    "the order\n",
    "</strong>\n",
    "or\n",
    "<strong>\n",
    "structure\n",
    "</strong>\n",
    "of words\n",
    "<strong>\n",
    "is discarded\n",
    "</strong>\n",
    ". That’s why it’s called a\n",
    "<strong>\n",
    "bag\n",
    "</strong>\n",
    "of words. This model is trying to understand whether a known word occurs in a document, but don’t know where is that word in the document.\n",
    "</p>\n",
    "<p id=\"83a6\">\n",
    "The intuition is that\n",
    "<strong>\n",
    "similar documents\n",
    "</strong>\n",
    "have\n",
    "<strong>\n",
    "similar contents\n",
    "</strong>\n",
    ". Also, from a content, we can learn something about the meaning of the document.\n",
    "</p>\n",
    "<h2 id=\"8ceb\">\n",
    "<strong>\n",
    "Example\n",
    "</strong>\n",
    "</h2>\n",
    "<p id=\"5920\">\n",
    "Let’s see what are the steps to create a bag-of-words model. In this example, we’ll use only four sentences to see how this model works. In the real-world problems, you’ll work with much bigger amounts of data.\n",
    "</p>\n",
    "<p id=\"59d9\">\n",
    "<strong>\n",
    "1. Load the Data\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/512/1*JTi6Bnodv2sui50F96v7-Q.png\"/>\n",
    "<p id=\"465e\">\n",
    "Let’s say that this is our data and we want to load it as an array.\n",
    "</p>\n",
    "<code>\n",
    "I like this movie, it's funny.<br/>\n",
    "I hate this movie.<br/>\n",
    "This was awesome! I like it.<br/>\n",
    "Nice one. I love it.\n",
    "</code>\n",
    "<p id=\"1cfc\">\n",
    "To achieve this we can simply read the file and split it by lines.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"reviews.txt\", \"r\") as file:\n",
    "    documents = file.read().splitlines()\n",
    "    \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"b74c\">\n",
    "<strong>\n",
    "2.\n",
    "</strong>\n",
    "<strong>\n",
    "Design the Vocabulary\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/512/1*AFUcM9S6FwX7RNTW4zqtLQ.png\"/>\n",
    "<p id=\"d008\">\n",
    "Let’s get all the unique words from the four loaded sentences ignoring the case, punctuation, and one-character tokens. These words will be our vocabulary (known words).\n",
    "</p>\n",
    "<p id=\"dc4a\">\n",
    "We can use the\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">\n",
    "<strong>\n",
    "CountVectorizer\n",
    "</strong>\n",
    "</a>\n",
    "class from the sklearn library to design our vocabulary. We’ll see how we can use it after reading the next step, too.\n",
    "</p>\n",
    "<p id=\"d817\">\n",
    "<strong>\n",
    "3. Create the Document Vectors\n",
    "</strong>\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/256/1*90Wv4B73KktRNU9NcYdpjg.png\"/>\n",
    "<p id=\"2a55\">\n",
    "Next, we need to score the words in each document. The task here is to convert each raw text into a vector of numbers. After that, we can use these vectors as input for a machine learning model. The simplest scoring method is to mark the presence of words with 1 for present and 0 for absence.\n",
    "</p>\n",
    "<p id=\"02b3\">\n",
    "Now, let’s see how we can create a bag-of-words model using the mentioned above CountVectorizer class.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the libraries we need\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2. Design the Vocabulary\n",
    "# The default token pattern removes tokens of a single character. That's why we don't have the \"I\" and \"s\" tokens in the output\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 3. Create the Bag-of-Words Model\n",
    "bag_of_words = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Show the Bag-of-Words Model as a pandas DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p id=\"513d\">\n",
    "Here are our sentences. Now we can see how the bag-of-words model works.\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/724/1*LtMJ1qSiIuEzZDqB-RQbjw.png\"/>\n",
    "<h2 id=\"efe2\">\n",
    "Additional Notes on the Bag of Words Model\n",
    "</h2>\n",
    "<img src=\"https://miro.medium.com/max/512/1*JvmcnIYVAzxHYdrxtmMa3Q.png\"/>\n",
    "<p id=\"d6dc\">\n",
    "The\n",
    "<strong>\n",
    "complexity\n",
    "</strong>\n",
    "of the bag-of-words model comes in deciding how to\n",
    "<strong>\n",
    "design the vocabulary\n",
    "</strong>\n",
    "of known words (tokens) and how to\n",
    "<strong>\n",
    "score the presence\n",
    "</strong>\n",
    "of known words.\n",
    "</p>\n",
    "<p id=\"92aa\">\n",
    "<strong>\n",
    "Designing the Vocabulary\n",
    "</strong>\n",
    "<br/>\n",
    "When the vocabulary\n",
    "<strong>\n",
    "size increases\n",
    "</strong>\n",
    ", the vector representation of the documents also increases. In the example above, the length of the document vector is equal to the number of known words.\n",
    "</p>\n",
    "<p id=\"c0e9\">\n",
    "In some cases, we can have a\n",
    "<strong>\n",
    "huge amount of data\n",
    "</strong>\n",
    "and in this cases, the length of the vector that represents a document might be\n",
    "<strong>\n",
    "thousands or millions\n",
    "</strong>\n",
    "of elements. Furthermore, each document may contain\n",
    "<strong>\n",
    "only a few of the known words\n",
    "</strong>\n",
    "in the vocabulary.\n",
    "</p>\n",
    "<p id=\"5365\">\n",
    "Therefore the vector representations will have a\n",
    "<strong>\n",
    "lot of zeros\n",
    "</strong>\n",
    ". These vectors which have a lot of zeros are called\n",
    "<strong>\n",
    "sparse vectors\n",
    "</strong>\n",
    ". They require more memory and computational resources.\n",
    "</p>\n",
    "<p id=\"ece1\">\n",
    "We can\n",
    "<strong>\n",
    "decrease\n",
    "</strong>\n",
    "the\n",
    "<strong>\n",
    "number of the known words\n",
    "</strong>\n",
    "when using a bag-of-words model to decrease the required memory and computational resources. We can use the\n",
    "<strong>\n",
    "text cleaning techniques\n",
    "</strong>\n",
    "we’ve already seen in this article before we create our bag-of-words model:\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"8007\">\n",
    "<strong>\n",
    "Ignoring the case\n",
    "</strong>\n",
    "of the words\n",
    "</li>\n",
    "<li id=\"498b\">\n",
    "<strong>\n",
    "Ignoring punctuation\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"cda7\">\n",
    "<strong>\n",
    "Removing\n",
    "</strong>\n",
    "the\n",
    "<strong>\n",
    "stop words\n",
    "</strong>\n",
    "from our documents\n",
    "</li>\n",
    "<li id=\"2db7\">\n",
    "Reducing the words to their base form (\n",
    "<strong>\n",
    "Text Lemmatization and Stemming\n",
    "</strong>\n",
    ")\n",
    "</li>\n",
    "<li id=\"6ae2\">\n",
    "<strong>\n",
    "Fixing misspelled words\n",
    "</strong>\n",
    "</li>\n",
    "</ul>\n",
    "<p id=\"a398\">\n",
    "Another more complex way to create a vocabulary is to use\n",
    "<strong>\n",
    "grouped words\n",
    "</strong>\n",
    ". This changes the\n",
    "<strong>\n",
    "scope\n",
    "</strong>\n",
    "of the vocabulary and allows the bag-of-words model to get\n",
    "<strong>\n",
    "more details\n",
    "</strong>\n",
    "about the document. This approach is called\n",
    "<strong>\n",
    "n-grams\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "<p id=\"864e\">\n",
    "An n-gram is a\n",
    "<strong>\n",
    "sequence of\n",
    "</strong>\n",
    "a number of\n",
    "<strong>\n",
    "items\n",
    "</strong>\n",
    "(words, letter, numbers, digits, etc.). In the context of\n",
    "<a href=\"https://en.wikipedia.org/wiki/Text_corpus\">\n",
    "<strong>\n",
    "text corpora\n",
    "</strong>\n",
    "</a>\n",
    ", n-grams typically refer to a sequence of words. A\n",
    "<strong>\n",
    "unigram\n",
    "</strong>\n",
    "is one word, a\n",
    "<strong>\n",
    "bigram\n",
    "</strong>\n",
    "is a sequence of two words, a\n",
    "<strong>\n",
    "trigram\n",
    "</strong>\n",
    "is a sequence of three words etc. The “n” in the “n-gram” refers to the number of the grouped words. Only the n-grams that appear in the corpus are modeled, not all possible n-grams.\n",
    "</p>\n",
    "<p id=\"c32b\">\n",
    "<strong>\n",
    "Example\n",
    "</strong>\n",
    "<br/>\n",
    "Let’s look at the all bigrams for the following sentence:\n",
    "<br/>\n",
    "<code>\n",
    "The office building is open today\n",
    "</code>\n",
    "</p>\n",
    "<p id=\"42a9\">\n",
    "All the bigrams are:\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"bac0\">\n",
    "the office\n",
    "</li>\n",
    "<li id=\"18eb\">\n",
    "office building\n",
    "</li>\n",
    "<li id=\"5afd\">\n",
    "building is\n",
    "</li>\n",
    "<li id=\"4e89\">\n",
    "is open\n",
    "</li>\n",
    "<li id=\"bc2b\">\n",
    "open today\n",
    "</li>\n",
    "</ul>\n",
    "<p id=\"96f5\">\n",
    "The\n",
    "<strong>\n",
    "bag-of-bigrams\n",
    "</strong>\n",
    "is more powerful than the bag-of-words approach.\n",
    "</p>\n",
    "\n",
    "<p id=\"ab9f\">\n",
    "<strong>\n",
    "Scoring Words\n",
    "<br/>\n",
    "</strong>\n",
    "Once, we have created our vocabulary of known words, we need to score the occurrence of the words in our data. We saw one very simple approach - the binary approach (1 for presence, 0 for absence).\n",
    "</p>\n",
    "<p id=\"0843\">\n",
    "Some additional scoring methods are:\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"cbb6\">\n",
    "<strong>\n",
    "Counts\n",
    "</strong>\n",
    ". Count the number of times each word appears in a document.\n",
    "</li>\n",
    "<li id=\"c226\">\n",
    "<strong>\n",
    "Frequencies\n",
    "</strong>\n",
    ". Calculate the frequency that each word appears in document out of all the words in the document.\n",
    "</li>\n",
    "</ul>\n",
    "<h2 id=\"cec9\">\n",
    "TF-IDF\n",
    "</h2>\n",
    "<p id=\"a8ae\">\n",
    "One problem with\n",
    "<strong>\n",
    "scoring word frequency\n",
    "</strong>\n",
    "is that the most frequent words in the document start to have the highest scores. These frequent words may not contain as much “\n",
    "<strong>\n",
    "informational gain\n",
    "</strong>\n",
    "” to the model compared with some rarer and domain-specific words. One approach to fix that problem is to\n",
    "<strong>\n",
    "penalize\n",
    "</strong>\n",
    "words that are\n",
    "<strong>\n",
    "frequent across all the documents\n",
    "</strong>\n",
    ". This approach is called TF-IDF.\n",
    "</p>\n",
    "<p id=\"75ba\">\n",
    "TF-IDF, short for\n",
    "<strong>\n",
    "term frequency-inverse document frequency\n",
    "</strong>\n",
    "is a\n",
    "<strong>\n",
    "statistical measure\n",
    "</strong>\n",
    "used to evaluate the importance of a word to a document in a collection or\n",
    "<a href=\"https://en.wikipedia.org/wiki/Text_corpus\">\n",
    "corpus\n",
    "</a>\n",
    ".\n",
    "</p>\n",
    "<p id=\"be4a\">\n",
    "The TF-IDF scoring value increases proportionally to the number of times a word appears in the document, but it is offset by the number of documents in the corpus that contain the word.\n",
    "</p>\n",
    "<p id=\"f64d\">\n",
    "Let’s see the formula used to calculate a TF-IDF score for a given term\n",
    "<strong>\n",
    "x\n",
    "</strong>\n",
    "within a document\n",
    "<strong>\n",
    "y\n",
    "</strong>\n",
    ".\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*V9ac4hLVyms79jl65Ym_Bw.png\"/>\n",
    "<p id=\"6ba7\">\n",
    "Now, let’s split this formula a little bit and see how the different parts of the formula work.\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"9a39\">\n",
    "<strong>\n",
    "Term Frequency (TF)\n",
    "</strong>\n",
    ": a scoring of the frequency of the word in the current document.\n",
    "</li>\n",
    "</ul>\n",
    "<br/>\n",
    "<img src=\"https://miro.medium.com/max/926/1*V3qfsHl0t-bV5kA0mlnsjQ.png\"/>\n",
    "<br/>\n",
    "<ul>\n",
    "<li id=\"9c81\">\n",
    "<strong>\n",
    "Inverse Term Frequency (ITF)\n",
    "</strong>\n",
    ": a scoring of how rare the word is across documents.\n",
    "</li>\n",
    "</ul>\n",
    "<br/>\n",
    "<img src=\"https://miro.medium.com/max/890/1*wvPGL02y36QL7-tdG1BT1A.png\"/>\n",
    "<br/>\n",
    "<ul>\n",
    "<li id=\"2d0d\">\n",
    "Finally, we can use the previous formulas to calculate the\n",
    "<strong>\n",
    "TF-IDF score\n",
    "</strong>\n",
    "for a given term like this:\n",
    "</li>\n",
    "</ul>\n",
    "<br/>\n",
    "<img src=\"https://miro.medium.com/max/588/1*D2UA6xj9KqcH6amzVj5Y5g.png\"/>\n",
    "<br/>\n",
    "<p id=\"86f5\">\n",
    "<strong>\n",
    "Example\n",
    "<br/>\n",
    "</strong>\n",
    "In Python, we can use the\n",
    "<strong>\n",
    "TfidfVectorizer\n",
    "</strong>\n",
    "class from the sklearn library to calculate the TF-IDF scores for given documents. Let’s use the same sentences that we have used with the bag-of-words example.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "values = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<p id=\"3896\">\n",
    "Again, I’ll add the sentences here for an easy comparison and better understanding of how this approach is working.\n",
    "</p>\n",
    "<img src=\"https://miro.medium.com/max/724/1*LtMJ1qSiIuEzZDqB-RQbjw.png\"/>\n",
    "<h1 id=\"8a9b\">\n",
    "Summary\n",
    "</h1>\n",
    "<p id=\"511f\">\n",
    "In this blog post, you learn the basics of the NLP for text. More specifically you have learned the following concepts with additional details:\n",
    "</p>\n",
    "<ul>\n",
    "<li id=\"e20b\">\n",
    "<strong>\n",
    "NLP\n",
    "</strong>\n",
    "is used to apply\n",
    "<strong>\n",
    "machine learning algorithms\n",
    "</strong>\n",
    "to\n",
    "<strong>\n",
    "text\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "speech\n",
    "</strong>\n",
    ".\n",
    "</li>\n",
    "<li id=\"71a4\">\n",
    "NLTK (\n",
    "<strong>\n",
    "Natural Language Toolkit\n",
    "</strong>\n",
    ") is a\n",
    "<strong>\n",
    "leading platform\n",
    "</strong>\n",
    "for building Python programs to work with\n",
    "<strong>\n",
    "human language data\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"973b\">\n",
    "<strong>\n",
    "Sentence tokenization\n",
    "</strong>\n",
    "is the problem of\n",
    "<strong>\n",
    "dividing a string\n",
    "</strong>\n",
    "of written language\n",
    "<strong>\n",
    "into\n",
    "</strong>\n",
    "its component\n",
    "<strong>\n",
    "sentences\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"b29c\">\n",
    "<strong>\n",
    "Word tokenization\n",
    "</strong>\n",
    "is the problem of\n",
    "<strong>\n",
    "dividing a string\n",
    "</strong>\n",
    "of written language\n",
    "<strong>\n",
    "into\n",
    "</strong>\n",
    "its component\n",
    "<strong>\n",
    "words\n",
    "</strong>\n",
    "</li>\n",
    "<li id=\"fcd0\">\n",
    "The goal of both\n",
    "<strong>\n",
    "stemming\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "lemmatization\n",
    "</strong>\n",
    "is to\n",
    "<strong>\n",
    "reduce\n",
    "</strong>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Inflection\">\n",
    "<strong>\n",
    "inflectional\n",
    "</strong>\n",
    "</a>\n",
    "<strong>\n",
    "forms\n",
    "</strong>\n",
    "and sometimes derivationally related forms\n",
    "<strong>\n",
    "</strong>\n",
    "of a\n",
    "<strong>\n",
    "word to\n",
    "</strong>\n",
    "a\n",
    "<strong>\n",
    "common base form\n",
    "</strong>\n",
    ".\n",
    "</li>\n",
    "<li id=\"ed1b\">\n",
    "<strong>\n",
    "Stop words\n",
    "</strong>\n",
    "are words which are filtered out before or after processing of text. They\n",
    "<strong>\n",
    "usually\n",
    "</strong>\n",
    "refer to the\n",
    "<strong>\n",
    "most common words\n",
    "</strong>\n",
    "in a language.\n",
    "</li>\n",
    "<li id=\"8a86\">\n",
    "A\n",
    "<strong>\n",
    "regular expression is\n",
    "</strong>\n",
    "a sequence of characters that define a\n",
    "<strong>\n",
    "search pattern\n",
    "</strong>\n",
    ".\n",
    "</li>\n",
    "<li id=\"c00c\">\n",
    "The\n",
    "<strong>\n",
    "bag-of-words\n",
    "</strong>\n",
    "model is a\n",
    "<strong>\n",
    "popular\n",
    "</strong>\n",
    "and\n",
    "<strong>\n",
    "simple\n",
    "</strong>\n",
    "<strong>\n",
    "feature extraction technique\n",
    "</strong>\n",
    "used when we work with text. It describes the occurrence of each word within a document.\n",
    "</li>\n",
    "<li id=\"cb8d\">\n",
    "<strong>\n",
    "TF-IDF\n",
    "</strong>\n",
    "is a\n",
    "<strong>\n",
    "statistical measure\n",
    "</strong>\n",
    "used to\n",
    "<strong>\n",
    "evaluate the importance\n",
    "</strong>\n",
    "<strong>\n",
    "of\n",
    "</strong>\n",
    "a\n",
    "<strong>\n",
    "word\n",
    "</strong>\n",
    "to a document in a collection or\n",
    "<a href=\"https://en.wikipedia.org/wiki/Text_corpus\">\n",
    "corpus\n",
    "</a>\n",
    ".\n",
    "</li>\n",
    "</ul>\n",
    "<p id=\"a9f9\">\n",
    "Awesome! Now we know the basics of how to extract features from a text. Then, we can use these features as an input for machine learning algorithms.\n",
    "</p>\n",
    "<p id=\"d2cc\">\n",
    "Do you want to see\n",
    "<strong>\n",
    "all the concepts\n",
    "</strong>\n",
    "used in\n",
    "<strong>\n",
    "one more big example\n",
    "</strong>\n",
    "?\n",
    "<br/>\n",
    "-\n",
    "<a href=\"https://github.com/Ventsislav-Yordanov/Blog-Examples/blob/master/Intro%20to%20NLP%20-%20Cleaning%20Review%20Texts%20Example/Cleaning%20Review%20Texts%20Example.ipynb\">\n",
    "Here you are\n",
    "</a>\n",
    "! If you’re reading from mobile, please scroll down to the end and click the “\n",
    "<em>\n",
    "Desktop version\n",
    "</em>\n",
    "” link.\n",
    "</p>\n",
    "<h1 id=\"df57\">\n",
    "Resources\n",
    "</h1>\n",
    "<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Natural_language_processing\">https://en.wikipedia.org/wiki/Natural_language_processing</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"http://www.nltk.org/\">http://www.nltk.org/</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Text_segmentation\">https://en.wikipedia.org/wiki/Text_segmentation</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Lemmatisation\">https://en.wikipedia.org/wiki/Lemmatisation</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Stemming\">https://en.wikipedia.org/wiki/Stemming</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\">https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Stop_words\">https://en.wikipedia.org/wiki/Stop_words</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Regular_expression\">https://en.wikipedia.org/wiki/Regular_expression</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://docs.python.org/3/library/re.html?highlight=regex\">https://docs.python.org/3/library/re.html?highlight=regex</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://machinelearningmastery.com/gentle-introduction-bag-words-model/\">https://machinelearningmastery.com/gentle-introduction-bag-words-model/</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://chrisalbon.com/machine_learning/preprocessing_text/bag_of_words/\">https://chrisalbon.com/machine_learning/preprocessing_text/bag_of_words/</a><a>\n",
    "<br>\n",
    "</a><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\">https://en.wikipedia.org/wiki/Tf%E2%80%93idf</a><a></a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "deepnoteSessionId": "391a3993-ce09-49d7-a274-f49f1e2914bb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
